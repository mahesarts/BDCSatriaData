{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing BDC.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHjXotbTTavy"
      },
      "source": [
        "Import Package dan Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSWaoDKRTav2"
      },
      "source": [
        "import re\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "import string\n",
        "import nltk\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4Do_XIXTav8"
      },
      "source": [
        "test=pd.read_excel('drive/My Drive/Data BDC - Satria Data 2020/Data Uji/Data Uji BDC.xlsx')\n",
        "train=pd.read_excel('drive/My Drive/Data BDC - Satria Data 2020/Data Latih/Data Latih BDC.xlsx')\n",
        "testoriginal=test.copy()\n",
        "trainoriginal=train.copy()\n",
        "dataset=train.copy()\n",
        "dataset=dataset.append(test)\n",
        "dataset=dataset.reset_index()\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKTF3-36eT_X"
      },
      "source": [
        "Penghilangan simbol dan perubahan menjadi huruf kecil pada kolom narasi dan judul"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YwrWObcTawx"
      },
      "source": [
        "#ilangin simbol\n",
        "dataset['narasibersih'] = dataset['narasi'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
        "dataset['narasibersih'] = dataset['narasibersih'].str.lower()\n",
        "dataset['judulbersih'] = dataset['judul'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
        "dataset['judulbersih'] = dataset['judulbersih'].str.lower()\n",
        "dataset.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6Od4hGjeFP-"
      },
      "source": [
        "Import Package untuk Penerjemahan data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCjAYYoyTav_"
      },
      "source": [
        "pip install googletrans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlHv3VBOTawE"
      },
      "source": [
        "from googletrans import Translator\n",
        "import time\n",
        "translator = Translator()\n",
        "narasi=dataset['narasibersih']\n",
        "judul=dataset['judulbersih']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ID1FHWXlTaxa"
      },
      "source": [
        "for i in range (len(narasi)):\n",
        "  translation = translator.translate(narasi[i], dest='id')\n",
        "  if translation.src=='en':\n",
        "    dataset.iloc[[i],[5]]=translation.text\n",
        "    print(i, translation.origin, '->',translation.text)\n",
        "  if i%400==0:\n",
        "    time.sleep(10)\n",
        "    translator = Translator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeOYpz6iTaxe"
      },
      "source": [
        "for i in range (len(judul)):\n",
        "  translation = translator.translate(judul[i], dest='id')\n",
        "  if translation.src=='en':\n",
        "    dataset.iloc[[i],[6]]=translation.text\n",
        "    print(i, translation.origin, '->',translation.text)\n",
        "  if i%400==0:\n",
        "    time.sleep(10)\n",
        "    translator = Translator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-J5YMRGel3v"
      },
      "source": [
        "Menghapus kata yang terdiri dari 2 huruf atau kurang serta tokenisasi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIcb4wtpTaxo"
      },
      "source": [
        "#lowercase\n",
        "dataset['narasibersih'] = dataset['narasibersih'].str.lower()\n",
        "dataset['judulbersih'] = dataset['judulbersih'].str.lower()\n",
        "#ilangin kata yang panjangnya kurang dari 2 huruf\n",
        "dataset['narasibersih'] = dataset['narasibersih'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>2]))\n",
        "dataset['judulbersih'] = dataset['judulbersih'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>2]))\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmQ1Q7uBTaxu"
      },
      "source": [
        "#tokenize \n",
        "tokenized_narasi = dataset['narasibersih'].apply(lambda x: x.split())\n",
        "tokenized_judul = dataset['judulbersih'].apply(lambda x: x.split())\n",
        "tokenized_judul.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iPmtoBtTax0"
      },
      "source": [
        "tokenized_narasi.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wETRjAedTax4"
      },
      "source": [
        "print(len(tokenized_narasi))\n",
        "print(len(tokenized_judul))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qoe3eRlfTawL"
      },
      "source": [
        "Autocorrect"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZDiJ0GdTawP"
      },
      "source": [
        "import io\n",
        "import time\n",
        "from datetime import timedelta\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "import gensim\n",
        "from gensim.models.wrappers import FastText\n",
        "import shutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yYbB5XiTawM"
      },
      "source": [
        "#downloading model\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.id.300.bin.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZc4Q-BtTawS"
      },
      "source": [
        "import os\n",
        "os.mkdir('model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kp0WlejnTawX"
      },
      "source": [
        "shutil.copy2('drive/My Drive/cc.id.300.bin.gz','model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efmwMfxsTawb"
      },
      "source": [
        "!gunzip 'model/cc.id.300.bin.gz'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xn6rXVMyTawf"
      },
      "source": [
        "model=FastText.load_fasttext_format('model/cc.id.300.bin')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elcBVPK7Tawk"
      },
      "source": [
        "words=list(model.wv.vocab)\n",
        "w_rank={}\n",
        "for i,word in enumerate (words):\n",
        "  w_rank[word]=i\n",
        "WORDS=w_rank"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvNTY_NbTawn"
      },
      "source": [
        "import itertools\n",
        "dict(itertools.islice(WORDS.items(),10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH6etqFJTawq"
      },
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "def words(text): return re.findall(r'\\w+',text.lower())\n",
        "\n",
        "def P(word):\n",
        "  return - WORDS.get(word,0)\n",
        "\n",
        "def correction(word):\n",
        "  return max(candidates(word),key=P)\n",
        "\n",
        "def candidates(word):\n",
        "  return (known([word]) or known(edits1(word)) or known (edits2(word)) or [word])\n",
        "\n",
        "def known(words):\n",
        "  return set(w for w in words if w in WORDS)\n",
        "\n",
        "def edits1(word):\n",
        "  letters='abcdefghijklmnopqrstuvwxyz'\n",
        "  splits=[(word[:i], word[i:]) for i in range(len(word)+1)]\n",
        "  deletes=[L+R[1:] for L, R in splits if R]\n",
        "  transposes=[L+R[1]+R[0]+R[2:] for L, R in splits if len(R)>1]\n",
        "  replaces=[L+c+R[1:] for L, R in splits if R for c in letters]\n",
        "  inserts=[L+c+R for L, R in splits for c in letters]\n",
        "  return set(deletes+transposes+replaces+inserts)\n",
        "\n",
        "def edits2(word):\n",
        "  return(e2 for e1 in edits1(word) for e2 in edits1(e1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yucsJHK3TayH"
      },
      "source": [
        "#Autocorrection\n",
        "for i in range(len(tokenized_narasi)):\n",
        "  katadasar=[]\n",
        "  kalimat = tokenized_narasi[i]\n",
        "  for j in kalimat:\n",
        "    katadasar.append(correction(j))\n",
        "  print('baris ke-',i)\n",
        "  tokenized_narasi[i] = katadasar\n",
        "tokenized_narasi.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLe5i1tnTayO"
      },
      "source": [
        "#Autocorrection\n",
        "for i in range(len(tokenized_judul)):\n",
        "  katadasar=[]\n",
        "  kalimat = tokenized_judul[i]\n",
        "  for j in kalimat:\n",
        "    katadasar.append(correction(j))\n",
        "  print('baris ke-',i)\n",
        "  tokenized_judul[i] = katadasar\n",
        "tokenized_judul.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sigUEdm2Tayp"
      },
      "source": [
        "tokenized_narasi.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5RpbO4CTayt"
      },
      "source": [
        "tokenized_judul.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1gusdTLTay5"
      },
      "source": [
        "for i in range(len(tokenized_narasi)):\n",
        "    tokenized_narasi[i] = ' '.join(tokenized_narasi[i])\n",
        "for i in range(len(tokenized_judul)):\n",
        "    tokenized_judul[i] = ' '.join(tokenized_judul[i])\n",
        "\n",
        "dataset['narasibersih'] = tokenized_narasi\n",
        "dataset['judulbersih'] = tokenized_judul\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UagNIZOOTaz0"
      },
      "source": [
        "Fitur Ekstraksi Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKwFB-rBTaz1"
      },
      "source": [
        "# Download Stopwords indonesia\n",
        "nltk.download('stopwords')\n",
        "swords=nltk.corpus.stopwords.words('indonesian')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCvtXEpwTaz7"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "bow_vectorizer = CountVectorizer(max_df=0.90, min_df=3, max_features=1000, stop_words = swords)\n",
        "bow1 = bow_vectorizer.fit_transform(dataset['narasibersih'])\n",
        "print(bow_vectorizer.get_feature_names())\n",
        "bow2 = bow_vectorizer.fit_transform(dataset['judulbersih'])\n",
        "print(bow_vectorizer.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R85TVjccTa0A"
      },
      "source": [
        "df_bulan=pd.DataFrame(arrbulantest)\n",
        "df_tanggal=pd.DataFrame(arrtanggaltest)\n",
        "df_tahun=pd.DataFrame(arrtahuntest)\n",
        "df_bulan.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vNHx7hwTa0N"
      },
      "source": [
        "df_bow1 = pd.DataFrame(bow1.todense())\n",
        "df_bow2 = pd.DataFrame(bow2.todense())\n",
        "df_bow=pd.concat([df_tanggal,df_bulan,df_tahun,df_bow1,df_bow2],axis=1)\n",
        "df_bow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DU8KCiS3Ta0l"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "df_bow=sc_X.fit_transform(df_bow)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tfh5Ofm0Ta0n"
      },
      "source": [
        "dfbowtest=df_bow[4231:,:]\n",
        "dfbowtrain=df_bow[:4231,:]\n",
        "print(len(dfbowtest))\n",
        "print(len(dfbowtrain))\n",
        "trainlabel=pd.DataFrame(train['label'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}